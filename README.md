# Explainability Methods in Music Emotion Recognition ğŸ¶

This repository accompanies the Masterâ€™s thesis  
**â€œExplainability Methods in Music Emotion Recognitionâ€**  
*Giacomo Zuliani, Politecnico di Torino, 2025*

ğŸ“„ [Read the Thesis (PDF)](./Giacomo_s_thesis_2.pdf)

---

## ğŸ“š Thesis Overview

The thesis investigates how **explainability** can be integrated into **Music Emotion Recognition (MER)** models, which are often treated as opaque black boxes.

Two complementary approaches were explored:

1. **Feature-based route**  
   - Uses symbolic and mid-level musical features (e.g., chroma, chords, perceptual descriptors such as dissonance or rhythmic stability).  
   - These features allow interpretable models (linear regression, shallow networks), helping researchers and musicians understand *which* musical properties drive emotional perception.

2. **Perceptual route (ViT + LRP + Sonification)**  
   - A Vision Transformer (ViT) was fine-tuned on spectrograms to classify clips as **Happy** or **Sad**.  
   - Explanations were derived using **Layer-wise Relevance Propagation (LRP)**.  
   - Instead of only visualizing attribution maps, the explanations were **sonified**: louder segments in the reconstructed audio correspond to the parts most relevant for the modelâ€™s decision.  
   - This turns explanations into something we can *hear*, making the modelâ€™s reasoning more intuitive and perceptually aligned.

---

## ğŸ§ Listening Examples

A set of audio examples is provided to demonstrate the sonification process.  
You can directly listen to them here:

ğŸ‘‰ **[Interactive Audio Examples on GitHub Pages](https://giacomozu.github.io/Explainability-Methods-in-Music-Emotion-Recognition/)**

The examples include:

- âœ… Correctly classified *Happy* and *Sad* excerpts (original vs. sonified).  
- âš ï¸ Misclassified excerpts (e.g., a Happy clip predicted as Sad), with both original and sonified versions.  

Together, they represent the four quadrants of the confusion matrix.

---

## ğŸ“‚ Repository Structure

examples/ # Original and sonified audio clips (WAV)
docs/index.html # Static page with embedded audio players (GitHub Pages)
README.md # Project description (this file)


---

## ğŸ”— Reference in Thesis

This repository is referenced in the thesis for sonification experiments:

> *â€œListening examples (original vs. sonified) are available online at the companion GitHub repository.â€*

Citation (APA style):

Zuliani, G. (2025). *Explainability Methods in Music Emotion Recognition* (Masterâ€™s thesis, Politecnico di Torino).  
Available at: [https://github.com/giacomozu/Explainability-Methods-in-Music-Emotion-Recognition](https://github.com/giacomozu/Explainability-Methods-in-Music-Emotion-Recognition)

---

## ğŸš€ Future Work

- Extend the set of examples with more genres and emotions.  
- Combine audio explanations with **visual heatmaps** in a multimodal interface.  
- Explore applications in **music recommendation** and **creative tools for composers**.

---

## ğŸ‘¤ Author

**Giacomo Zuliani**  
Master of Science in Energy Engineering  
Politecnico di Torino (2025)


